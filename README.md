# EECS-6893-Big-Data-Analysis

**Ticketmaster éŸ³ä¹æ´»åŠ¨å¤§æ•°æ®åˆ†æé¡¹ç›®**

Final Project - åŸºäº Ticketmaster API çš„éŸ³ä¹æ´»åŠ¨æ•°æ®é‡‡é›†ã€ETLã€åˆ†æå’Œæœºå™¨å­¦ä¹ é¢„æµ‹

---

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®é€šè¿‡ Ticketmaster Discovery API é‡‡é›†ç¾å›½å„ä¸»è¦åŸå¸‚çš„éŸ³ä¹æ´»åŠ¨æ•°æ®ï¼Œåˆ©ç”¨ Apache Spark åœ¨ Google Cloud Dataproc é›†ç¾¤ä¸Šè¿›è¡Œå¤§æ•°æ®å¤„ç†ã€åˆ†æå’Œæœºå™¨å­¦ä¹ å»ºæ¨¡ï¼ŒæŒ–æ˜éŸ³ä¹æ´»åŠ¨çš„åœ°åŸŸåˆ†å¸ƒã€æ—¶é—´è¶‹åŠ¿ã€è‰ºæœ¯å®¶çƒ­åº¦ç­‰æ´å¯Ÿã€‚

## é¡¹ç›®ç»“æ„

```
EECS-6893-Big-Data-Analysis/
â”œâ”€â”€ fetch_data.py              # æ•°æ®é‡‡é›†è„šæœ¬ï¼šä» Ticketmaster API æŠ“å–éŸ³ä¹æ´»åŠ¨æ•°æ®
â”œâ”€â”€ parse_data.py              # æœ¬åœ°æ•°æ®è§£æè„šæœ¬ï¼šå°† JSON è½¬æ¢ä¸º Pandas DataFrame
â”œâ”€â”€ spark_etl_events.py        # Spark ETL ä½œä¸šï¼šæ¸…æ´—å’Œè½¬æ¢åŸå§‹æ•°æ®ä¸º Parquet
â”œâ”€â”€ spark_analysis_events.py   # Spark åˆ†æä½œä¸šï¼šç”Ÿæˆå¤šç»´åº¦ç»Ÿè®¡åˆ†æ
â”œâ”€â”€ spark_ml_events.py         # Spark ML ä½œä¸šï¼šé¢„æµ‹è‰ºæœ¯å®¶æœªæ¥çƒ­åº¦
â”œâ”€â”€ README.md                  # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â””â”€â”€ ticketmaster_raw/          # åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•
    â””â”€â”€ dt=2025-11-21/         # æŒ‰æ—¥æœŸåˆ†åŒº
        â”œâ”€â”€ events_AllUS.jsonl
        â”œâ”€â”€ events_Chicago.jsonl
        â”œâ”€â”€ events_Houston.jsonl
        â”œâ”€â”€ events_LosAngeles.jsonl
        â”œâ”€â”€ events_NewYork.jsonl
        â””â”€â”€ events_Phoenix.jsonl
```

---

## åŠŸèƒ½æ¨¡å—

### 1. æ•°æ®é‡‡é›† (`fetch_data.py`)

**åŠŸèƒ½ï¼š** ä» Ticketmaster Discovery API è·å–éŸ³ä¹æ´»åŠ¨æ•°æ®

**ç‰¹æ€§ï¼š**
- æ”¯æŒå¤šä¸ª DMAï¼ˆDesignated Market Areaï¼‰åŒºåŸŸ
  - New York (345)
  - Los Angeles (324)
  - Chicago (249)
  - Houston (300)
  - Phoenix (359)
  - AllUS (200) - å…¨ç¾èŒƒå›´
- è‡ªåŠ¨åˆ†é¡µè·å–å®Œæ•´æ•°æ®é›†
- æŒ‰æ—¥æœŸåˆ†åŒºå­˜å‚¨ï¼ˆ`dt=YYYY-MM-DD`ï¼‰
- é€Ÿç‡é™åˆ¶ä¿æŠ¤ï¼Œé¿å… API é™æµ
- è¾“å‡ºæ ¼å¼ï¼šJSONLï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰

**ä½¿ç”¨æ–¹æ³•ï¼š**
```bash
python fetch_data.py
```

**é…ç½®ï¼š**
- API Keyï¼šåœ¨ä»£ç ä¸­è®¾ç½® `API_KEY`
- è¾“å‡ºç›®å½•ï¼š`OUTPUT_DIR = "ticketmaster_raw/"`

---

### 2. æœ¬åœ°æ•°æ®è§£æ (`parse_data.py`)

**åŠŸèƒ½ï¼š** å°†åŸå§‹ JSONL æ–‡ä»¶è§£æä¸ºç»“æ„åŒ–çš„ Pandas DataFrame

**æå–å­—æ®µï¼š**
- **åŸºæœ¬ä¿¡æ¯ï¼š** ID, Name, Date
- **è‰ºæœ¯å®¶ä¿¡æ¯ï¼š** Artist, Segment, Genre, SubGenre
- **ä»·æ ¼ä¿¡æ¯ï¼š** Price_Ranges_Type, Currency, Max, Min
- **åœºé¦†ä¿¡æ¯ï¼š** Venue, City, State, Country, Timezone
- **çƒ­åº¦æŒ‡æ ‡ï¼š** Upcoming_Events_Venue, Upcoming_Events_Artist
- **æ¨å¹¿ä¿¡æ¯ï¼š** Promoter

**ä½¿ç”¨æ–¹æ³•ï¼š**
```python
python parse_data.py
```

---

### 3. Spark ETL (`spark_etl_events.py`)

**åŠŸèƒ½ï¼š** åˆ†å¸ƒå¼æ•°æ®æ¸…æ´—å’Œè½¬æ¢ï¼Œç”Ÿæˆæ ‡å‡†åŒ–çš„ Parquet æ•°æ®é›†

**å¤„ç†æµç¨‹ï¼š**
1. è¯»å–åŸå§‹ JSONL æ–‡ä»¶
2. æ‰å¹³åŒ–åµŒå¥— JSON ç»“æ„
3. æå–å…³é”®å­—æ®µï¼ˆvenueã€artistã€classificationï¼‰
4. ç±»å‹è½¬æ¢ï¼ˆæ—¥æœŸã€æ•°å€¼ï¼‰
5. å»é‡ï¼ˆæŒ‰æ´»åŠ¨ IDï¼‰
6. è¿‡æ»¤ç¼ºå¤±å…³é”®å­—æ®µçš„è®°å½•
7. è¾“å‡ºä¸º Parquet æ ¼å¼

**ä½¿ç”¨æ–¹æ³•ï¼ˆGoogle Cloud Dataprocï¼‰ï¼š**
```bash
gcloud dataproc jobs submit pyspark spark_etl_events.py \
  --cluster=<your-cluster> \
  --region=us-east1 \
  -- --input gs://<bucket>/ticketmaster_raw/dt=*/events_*.jsonl \
     --output gs://<bucket>/ticketmaster_processed/events_parquet
```

**å¿…éœ€å‚æ•°ï¼š**
- `--input`: åŸå§‹æ•°æ®è·¯å¾„ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
- `--output`: æ¸…æ´—å Parquet è¾“å‡ºè·¯å¾„

---

### 4. Spark æ•°æ®åˆ†æ (`spark_analysis_events.py`)

**åŠŸèƒ½ï¼š** å¤šç»´åº¦ç»Ÿè®¡åˆ†æï¼Œç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ

**åˆ†æç»´åº¦ï¼š**
1. **å¹´åº¦ & ç±»å‹åˆ†æï¼š** å„å¹´ä»½å„éŸ³ä¹ç±»å‹çš„æ´»åŠ¨æ•°é‡
2. **åœ°åŸŸåˆ†æï¼š** Top 50 æ´»åŠ¨æœ€å¤šçš„åŸå¸‚
3. **è‰ºæœ¯å®¶çƒ­åº¦ï¼š** Top 50 å³å°†ä¸¾åŠæ´»åŠ¨æœ€å¤šçš„è‰ºæœ¯å®¶
4. **æ—¶é—´è¶‹åŠ¿ï¼š** å„æ˜ŸæœŸå‡ çš„æ´»åŠ¨åˆ†å¸ƒ

**ä½¿ç”¨æ–¹æ³•ï¼ˆGoogle Cloud Dataprocï¼‰ï¼š**
```bash
gcloud dataproc jobs submit pyspark spark_analysis_events.py \
  --cluster=<your-cluster> \
  --region=us-east1 \
  -- --input gs://<bucket>/ticketmaster_processed/events_parquet \
     --output gs://<bucket>/ticketmaster_analytics
```

**è¾“å‡ºæ–‡ä»¶ï¼š**
- `events_per_year_genre/`: å¹´åº¦ç±»å‹ç»Ÿè®¡
- `top_cities/`: Top åŸå¸‚æ’å
- `top_artists/`: Top è‰ºæœ¯å®¶æ’å
- `events_per_weekday/`: æ˜ŸæœŸåˆ†å¸ƒ

---

### 5. Spark æœºå™¨å­¦ä¹  (`spark_ml_events.py`)

**åŠŸèƒ½ï¼š** åŸºäºéšæœºæ£®æ—å›å½’æ¨¡å‹é¢„æµ‹è‰ºæœ¯å®¶æœªæ¥çƒ­åº¦

**ç›®æ ‡å˜é‡ï¼š**
- `Upcoming_Events_Artist`ï¼šè‰ºæœ¯å®¶å³å°†ä¸¾åŠçš„æ´»åŠ¨æ•°é‡ï¼ˆçƒ­åº¦ä»£ç†æŒ‡æ ‡ï¼‰

**ç‰¹å¾å·¥ç¨‹ï¼š**
- **ç±»åˆ«ç‰¹å¾ï¼š** Segment, Genre, SubGenre, Venue_City, Venue_State, Venue_Country
- **æ•°å€¼ç‰¹å¾ï¼š** Upcoming_Events_Venue, year, month, weekday
- **ç¼–ç æ–¹å¼ï¼š** StringIndexer + OneHotEncoder

**æ¨¡å‹é…ç½®ï¼š**
- ç®—æ³•ï¼šRandomForestRegressor
- æ ‘æ•°é‡ï¼š80
- æœ€å¤§æ·±åº¦ï¼š10
- è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†ï¼š80% / 20%

**è¯„ä¼°æŒ‡æ ‡ï¼š**
- RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰
- MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰
- RÂ²ï¼ˆå†³å®šç³»æ•°ï¼‰

**ä½¿ç”¨æ–¹æ³•ï¼ˆGoogle Cloud Dataprocï¼‰ï¼š**
```bash
gcloud dataproc jobs submit pyspark spark_ml_events.py \
  --cluster=<your-cluster> \
  --region=us-east1 \
  -- --input gs://<bucket>/ticketmaster_processed/events_parquet \
     --metrics-output gs://<bucket>/ticketmaster_ml/metrics \
     --model-output gs://<bucket>/ticketmaster_ml/models/rf_upcoming_artist
```

**è¾“å‡ºï¼š**
- è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆPipelineModelï¼‰
- è¯„ä¼°æŒ‡æ ‡ JSON æ–‡ä»¶

---

## æŠ€æœ¯æ ˆ

- **æ•°æ®é‡‡é›†ï¼š** Python, Requests, Ticketmaster Discovery API
- **æ•°æ®å¤„ç†ï¼š** Apache Spark (PySpark)
- **æœºå™¨å­¦ä¹ ï¼š** Spark MLlib (RandomForest, Pipeline)
- **äº‘å¹³å°ï¼š** Google Cloud Platform (Dataproc, Cloud Storage)
- **æ•°æ®æ ¼å¼ï¼š** JSONL, Parquet, CSV
- **æœ¬åœ°åˆ†æï¼š** Pandas, NumPy

---

## ç¯å¢ƒè¦æ±‚

### æœ¬åœ°ç¯å¢ƒ
```bash
pip install requests pandas numpy
```

### Spark ç¯å¢ƒï¼ˆDataprocï¼‰
- Python 3.7+
- PySpark 3.x
- Spark MLlib

---

## æ•°æ®æµç¨‹

```
1. æ•°æ®é‡‡é›†
   Ticketmaster API â†’ fetch_data.py â†’ ticketmaster_raw/*.jsonl

2. ETL å¤„ç†
   JSONL â†’ spark_etl_events.py â†’ Parquet (æ¸…æ´—åæ•°æ®)

3. åˆ†æ & ML
   â”œâ”€â”€ spark_analysis_events.py â†’ ç»Ÿè®¡åˆ†æç»“æœ (CSV)
   â””â”€â”€ spark_ml_events.py â†’ é¢„æµ‹æ¨¡å‹ + è¯„ä¼°æŒ‡æ ‡
```

---

## å¿«é€Ÿå¼€å§‹

### ğŸ¯ **æ–¹å¼ 1: ä½¿ç”¨å¤–éƒ¨æ•°æ®é›†ï¼ˆæ¨èï¼‰**

å¦‚æœä½ æœ‰å¤–éƒ¨ CSV æ•°æ®é›†ï¼ˆåŒ…å« SeatGeek, StubHub, Spotify æ•°æ®ï¼‰ï¼š

#### **Step 1: é…ç½® Dataproc**
```bash
# 1. ç¼–è¾‘é…ç½®æ–‡ä»¶
cp dataproc_config.json.example dataproc_config.json
# å¡«å…¥ä½ çš„ GCP é¡¹ç›®ä¿¡æ¯

# 2. åˆ›å»º Dataproc é›†ç¾¤
gcloud dataproc clusters create ticketmaster-cluster \
  --region=us-east1 \
  --num-workers=2 \
  --master-machine-type=n1-standard-4 \
  --worker-machine-type=n1-standard-4
```

è¯¦ç»†è®¾ç½®æŒ‡å—ï¼š**[DATAPROC_SETUP.md](DATAPROC_SETUP.md)**

#### **Step 2: ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹**
```bash
# Dataproc æ¨¡å¼ï¼ˆè‡ªåŠ¨æ•´åˆã€ä¸Šä¼ ã€æäº¤ä½œä¸šï¼‰
python quickstart_integration.py --mode dataproc
```

**è¿™ä¼šè‡ªåŠ¨ï¼š**
1. âœ… æ•´åˆå¤–éƒ¨æ•°æ®ï¼ˆæœ¬åœ°ï¼‰
2. âœ… ä¸Šä¼ åˆ° GCS
3. âœ… æäº¤ ETL ä½œä¸šï¼ˆDataprocï¼‰
4. âœ… æäº¤åˆ†æä½œä¸šï¼ˆDataprocï¼‰
5. âœ… æäº¤ ML ç¥¨ä»·é¢„æµ‹ï¼ˆDataprocï¼‰

å®Œæ•´æŒ‡å—ï¼š**[EXTERNAL_DATA_WORKFLOW.md](EXTERNAL_DATA_WORKFLOW.md)**

---

### ğŸ”§ **æ–¹å¼ 2: ä»…ä½¿ç”¨ Ticketmaster æ•°æ®**

#### **Step 1: é‡‡é›†æ•°æ®**
```bash
# é…ç½® API Key åè¿è¡Œ
python fetch_data.py
```

#### **Step 2: ä¸Šä¼ æ•°æ®åˆ° GCS**
```bash
# ä¸Šä¼ åŸå§‹æ•°æ®åˆ° GCS
gsutil -m cp -r ticketmaster_raw/ gs://<your-bucket>/

# ä¸Šä¼  Spark è„šæœ¬
gsutil cp spark_*.py gs://<your-bucket>/scripts/
```

#### **Step 3: æäº¤ Spark ETL ä½œä¸š**
```bash
gcloud dataproc jobs submit pyspark \
  gs://<bucket>/scripts/spark_etl_events.py \
  --cluster=<cluster-name> \
  --region=us-east1 \
  -- --input gs://<bucket>/ticketmaster_raw/dt=*/events_*.jsonl \
     --output gs://<bucket>/ticketmaster_processed/events_parquet
```

#### **Step 4: è¿è¡Œåˆ†æä½œä¸š**
```bash
gcloud dataproc jobs submit pyspark \
  gs://<bucket>/scripts/spark_analysis_events.py \
  --cluster=<cluster-name> \
  --region=us-east1 \
  -- --input gs://<bucket>/ticketmaster_processed/events_parquet \
     --output gs://<bucket>/ticketmaster_analytics
```

#### **Step 5: è®­ç»ƒ ML æ¨¡å‹**
```bash
gcloud dataproc jobs submit pyspark \
  gs://<bucket>/scripts/spark_ml_events.py \
  --cluster=<cluster-name> \
  --region=us-east1 \
  -- --input gs://<bucket>/ticketmaster_processed/events_parquet \
     --metrics-output gs://<bucket>/ticketmaster_ml/metrics \
     --model-output gs://<bucket>/ticketmaster_ml/models/rf_upcoming_artist
```

---

### ğŸ’» **æ–¹å¼ 3: æœ¬åœ°å¼€å‘æµ‹è¯•**

```bash
# æœ¬åœ°æ¨¡å¼ï¼ˆä¸éœ€è¦ Dataprocï¼‰
python quickstart_integration.py --mode local

# è¿™ä¼šç”Ÿæˆ enriched_events.csv ç”¨äºæœ¬åœ°æµ‹è¯•
```

---

## æ•°æ®å­—æ®µè¯´æ˜

| å­—æ®µå | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| ID | string | æ´»åŠ¨å”¯ä¸€æ ‡è¯†ç¬¦ |
| Name | string | æ´»åŠ¨åç§° |
| Date | string | æ´»åŠ¨æ—¥æœŸ (YYYY-MM-DD) |
| Artist | string | è‰ºæœ¯å®¶åç§° |
| Segment | string | æ´»åŠ¨å¤§ç±»ï¼ˆå¦‚ Musicï¼‰ |
| Genre | string | éŸ³ä¹ç±»å‹ï¼ˆå¦‚ Rock, Popï¼‰ |
| SubGenre | string | éŸ³ä¹å­ç±»å‹ |
| Promoter | string | æ¨å¹¿å•†åç§° |
| Venue | string | åœºé¦†åç§° |
| Venue_City | string | åœºé¦†æ‰€åœ¨åŸå¸‚ |
| Venue_State | string | åœºé¦†æ‰€åœ¨å·ï¼ˆå·ä»£ç ï¼‰ |
| Venue_Country | string | åœºé¦†æ‰€åœ¨å›½å®¶ |
| Venue_Timezone | string | åœºé¦†æ—¶åŒº |
| Upcoming_Events_Venue | int | è¯¥åœºé¦†å³å°†ä¸¾åŠçš„æ´»åŠ¨æ•° |
| Upcoming_Events_Artist | int | è¯¥è‰ºæœ¯å®¶å³å°†ä¸¾åŠçš„æ´»åŠ¨æ•° |

---

## é¡¹ç›®äº®ç‚¹

âœ… **å®Œæ•´çš„å¤§æ•°æ®å¤„ç†æµç¨‹**ï¼šä»æ•°æ®é‡‡é›†åˆ°åˆ†æå»ºæ¨¡  
âœ… **åˆ†å¸ƒå¼è®¡ç®—**ï¼šåˆ©ç”¨ Spark å¤„ç†å¤§è§„æ¨¡æ•°æ®  
âœ… **äº‘åŸç”Ÿæ¶æ„**ï¼šåŸºäº GCP Dataproc å’Œ Cloud Storage  
âœ… **å¤šç»´åº¦åˆ†æ**ï¼šåœ°åŸŸã€æ—¶é—´ã€ç±»å‹ã€è‰ºæœ¯å®¶çƒ­åº¦  
âœ… **æœºå™¨å­¦ä¹ åº”ç”¨**ï¼šé¢„æµ‹è‰ºæœ¯å®¶æœªæ¥çƒ­åº¦è¶‹åŠ¿  
âœ… **å¯æ‰©å±•è®¾è®¡**ï¼šæ”¯æŒæ–°å¢ DMA åŒºåŸŸå’Œç‰¹å¾ç»´åº¦

---

## ä½œè€…

EECS-6893 Big Data Analysis - Final Project

---

## License

MIT License
