#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Spark å¤šæ¨¡å‹è®­ç»ƒ - master_df.csv æ•°æ®

è®­ç»ƒ 6 ç§å›å½’æ¨¡å‹é¢„æµ‹äºŒçº§å¸‚åœºä»·æ ¼ï¼ˆSeatGeek å¹³å‡ä»·æ ¼ï¼‰:
  1. Linear Regression (æ™®é€šçº¿æ€§å›å½’)
  2. Lasso Regression (L1 æ­£åˆ™åŒ–)
  3. Elastic Net (L1+L2 æ­£åˆ™åŒ–)
  4. Decision Tree (å†³ç­–æ ‘)
  5. Random Forest (éšæœºæ£®æ—)
  6. Gradient Boosting Tree (æ¢¯åº¦æå‡æ ‘)

Usage:
æœ¬åœ°è¿è¡Œ:
    spark-submit spark_ml_multi_models.py \
      --input output/master_parquet \
      --output output/ml_multi_models

Dataproc:
    gcloud dataproc jobs submit pyspark spark_ml_multi_models.py \
      --cluster=<cluster-name> \
      --region=us-east1 \
      -- --input gs://bucket/output/master_parquet \
         --output gs://bucket/output/ml_multi_models
"""

import argparse
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator


def build_spark(app_name: str = "MultiModelML") -> SparkSession:
    spark = (
        SparkSession.builder
        .appName(app_name)
        .config("spark.sql.adaptive.enabled", "true")
        .getOrCreate()
    )
    return spark


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(  
        "--input",
        type=str,
        required=True,
        help="Input Parquet path from ETL step"
    )
    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="Output base path for models and metrics"
    )
    return parser.parse_args()


def main():
    args = parse_args()
    spark = build_spark()

    print(f"[INFO] Reading processed data from: {args.input}")
    df = spark.read.parquet(args.input)
    print("[INFO] Schema:")
    df.printSchema()

    # æ•°æ®å‡†å¤‡ï¼šåªä¿ç•™æœ‰äºŒçº§å¸‚åœºä»·æ ¼çš„è®°å½•
    print("[INFO] Preparing ML dataset...")
    df_ml = (
        df
        .filter(
            F.col("sg_avg_price").isNotNull() &
            (F.col("sg_avg_price") > 0) &
            F.col("tm_min_price").isNotNull() &
            F.col("artist").isNotNull() &
            F.col("genre").isNotNull()
        )
        # ç›®æ ‡å˜é‡ï¼šSeatGeek å¹³å‡ä»·æ ¼
        .withColumn("label", F.col("sg_avg_price").cast("double"))
        .filter(F.col("label") >= 0)
    )

    print(f"[INFO] ML dataset size: {df_ml.count()}")
    
    if df_ml.count() < 100:
        print("[ERROR] Not enough data for ML (< 100 records with sg_avg_price)")
        spark.stop()
        return

    # å®šä¹‰ç‰¹å¾
    # ç±»åˆ«ç‰¹å¾ï¼ˆéœ€è¦ç¼–ç ï¼‰
    categorical_cols = ["genre", "subgenre", "state"]
    
    # æ•°å€¼ç‰¹å¾
    numeric_cols = [
        "tm_min_price",
        "tm_max_price", 
        "price_range",
        "spotify_popularity",
        "spotify_followers",
        "sg_listing_count",
        "year",
        "month",
        "weekday"
    ]

    # å¡«å……ç¼ºå¤±å€¼
    print("[INFO] Filling missing values...")
    for col in numeric_cols:
        df_ml = df_ml.withColumn(
            col,
            F.when(F.col(col).isNull(), F.lit(0)).otherwise(F.col(col))
        )
    
    for col in categorical_cols:
        df_ml = df_ml.fillna({col: "Unknown"})

    # æ„å»ºç‰¹å¾å·¥ç¨‹ Pipeline
    print("[INFO] Building feature engineering pipeline...")
    
    # StringIndexer + OneHotEncoder å¤„ç†ç±»åˆ«ç‰¹å¾
    indexers = []
    encoders = []
    for col in categorical_cols:
        indexer = StringIndexer(
            inputCol=col,
            outputCol=f"{col}_idx",
            handleInvalid="keep"   # ä¿ç•™æœªè§è¿‡çš„ç±»åˆ«
        )
        encoder = OneHotEncoder(
            inputCols=[f"{col}_idx"],
            outputCols=[f"{col}_ohe"]
        )
        indexers.append(indexer)
        encoders.append(encoder)

    # ç»„åˆæ‰€æœ‰ç‰¹å¾
    feature_cols = [f"{col}_ohe" for col in categorical_cols] + numeric_cols
    assembler = VectorAssembler(
        inputCols=feature_cols,
        outputCol="features",
        handleInvalid="skip"  # è·³è¿‡åŒ…å«æ— æ•ˆå€¼çš„è¡Œ
    )

    # æ•°æ®é›†åˆ†å‰²
    train_data, test_data = df_ml.randomSplit([0.8, 0.2], seed=42)
    print(f"[INFO] Training samples: {train_data.count()}, Test samples: {test_data.count()}")

    # æ„å»ºå¹¶åº”ç”¨ç‰¹å¾å·¥ç¨‹ Pipeline
    print("[INFO] Applying feature engineering...")
    feature_pipeline = Pipeline(stages=indexers + encoders + [assembler])
    feature_model = feature_pipeline.fit(train_data)
    train_data = feature_model.transform(train_data)
    test_data = feature_model.transform(test_data)

    # ç¼“å­˜æ•°æ®ä»¥åŠ é€Ÿå¤šæ¬¡è®­ç»ƒ
    train_data = train_data.cache()
    test_data = test_data.cache()

    print(f"[INFO] Feature vector size: {train_data.select('features').head()[0].size}")

    # ============================================================
    # å®šä¹‰ 6 ç§å›å½’æ¨¡å‹
    # ============================================================
    print("\n" + "="*80)
    print("å®šä¹‰å¤šä¸ªå›å½’æ¨¡å‹")
    print("="*80)

    # 1. æ™®é€šçº¿æ€§å›å½’
    lr = LinearRegression(
        featuresCol="features",
        labelCol="label",
        maxIter=100
    )

    # 2. Lasso å›å½’ï¼ˆL1 æ­£åˆ™åŒ–ï¼‰
    lasso = LinearRegression(
        featuresCol="features",
        labelCol="label",
        regParam=0.1,
        elasticNetParam=1.0,  # 1.0 = çº¯ L1
        maxIter=100
    )

    # 3. Elastic Netï¼ˆL1 + L2 æ­£åˆ™åŒ–ï¼‰
    elastic_net = LinearRegression(
        featuresCol="features",
        labelCol="label",
        regParam=0.1,
        elasticNetParam=0.5,  # 0.5 = L1 å’Œ L2 æ··åˆ
        maxIter=100
    )

    # 4. å†³ç­–æ ‘
    dt = DecisionTreeRegressor(
        featuresCol="features",
        labelCol="label",
        maxDepth=15,
        seed=42
    )

    # 5. éšæœºæ£®æ—
    rf = RandomForestRegressor(
        featuresCol="features",
        labelCol="label",
        numTrees=80,
        maxDepth=12,
        seed=42
    )

    # 6. æ¢¯åº¦æå‡æ ‘
    gbt = GBTRegressor(
        featuresCol="features",
        labelCol="label",
        maxIter=50,
        maxDepth=6,
        seed=42
    )

    regression_models = {
        "linear_regression": lr,
        "lasso_regression": lasso,
        "elastic_net": elastic_net,
        "decision_tree": dt,
        "random_forest": rf,
        "gbt": gbt
    }

    print(f"[INFO] å°†è®­ç»ƒ {len(regression_models)} ä¸ªå›å½’æ¨¡å‹")

    # ============================================================
    # è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹
    # ============================================================
    evaluator_rmse = RegressionEvaluator(metricName="rmse", labelCol="label", predictionCol="prediction")
    evaluator_mae = RegressionEvaluator(metricName="mae", labelCol="label", predictionCol="prediction")
    evaluator_r2 = RegressionEvaluator(metricName="r2", labelCol="label", predictionCol="prediction")

    metrics_list = []
    
    for model_name, model in regression_models.items():
        print("\n" + "="*80)
        print(f"è®­ç»ƒæ¨¡å‹: {model_name}")
        print("="*80)

        # è®­ç»ƒæ¨¡å‹
        trained_model = model.fit(train_data)
        
        # é¢„æµ‹
        pred_df = trained_model.transform(test_data)

        # è¯„ä¼°
        rmse = evaluator_rmse.evaluate(pred_df)
        mae = evaluator_mae.evaluate(pred_df)
        r2 = evaluator_r2.evaluate(pred_df)

        print(f"[METRICS]")
        print(f"  RMSE (Root Mean Squared Error): ${rmse:.2f}")
        print(f"  MAE  (Mean Absolute Error):     ${mae:.2f}")
        print(f"  RÂ²   (R-squared):                {r2:.4f}")

        # æå–ç‰¹å¾é‡è¦æ€§ï¼ˆä»… Tree-based æ¨¡å‹ï¼‰
        if model_name in ["decision_tree", "random_forest", "gbt"]:
            print(f"\n[INFO] æå–ç‰¹å¾é‡è¦æ€§...")
            
            try:
                importances = trained_model.featureImportances.toArray()
                
                # è·å–ç‰¹å¾åç§°
                feature_names = []
                for col in feature_cols:
                    if col.endswith("_ohe"):
                        # OHE ç‰¹å¾ï¼šè·å–åŸå§‹åˆ—å
                        original_col = col.replace("_ohe", "")
                        # è·å–ç¼–ç åçš„ç»´åº¦æ•°
                        ohe_size = train_data.select(col).head()[0].size
                        for i in range(ohe_size):
                            feature_names.append(f"{original_col}_{i}")
                    else:
                        # æ•°å€¼ç‰¹å¾
                        feature_names.append(col)
                
                # é…å¯¹ç‰¹å¾åå’Œé‡è¦æ€§
                fi_pairs = list(zip(feature_names, importances))
                fi_sorted = sorted(fi_pairs, key=lambda x: x[1], reverse=True)
                
                # æ˜¾ç¤º Top 15 ç‰¹å¾
                print(f"\nTop 15 æœ€é‡è¦ç‰¹å¾:")
                for name, val in fi_sorted[:15]:
                    print(f"  {name:40s}: {val:.4f}")
                
                # ä¿å­˜ç‰¹å¾é‡è¦æ€§
                fi_output = f"{args.output}/feature_importance/{model_name}"
                print(f"[INFO] ä¿å­˜ç‰¹å¾é‡è¦æ€§åˆ°: {fi_output}")
                fi_df = spark.createDataFrame(fi_sorted, ["feature", "importance"])
                fi_df.coalesce(1).write.mode("overwrite").option("header", "true").csv(fi_output)
                
            except Exception as e:
                print(f"[WARN] æ— æ³•æå–ç‰¹å¾é‡è¦æ€§: {e}")

        # ä¿å­˜æ¨¡å‹
        model_path = f"{args.output}/models/{model_name}"
        print(f"[INFO] ä¿å­˜æ¨¡å‹åˆ°: {model_path}")
        trained_model.write().overwrite().save(model_path)

        # ä¿å­˜é¢„æµ‹æ ·ä¾‹
        predictions_sample = pred_df.select(
            "event_id",
            "artist",
            "genre",
            "city",
            "tm_min_price",
            F.col("label").alias("actual_price"),
            F.col("prediction").alias("predicted_price"),
            F.abs(F.col("label") - F.col("prediction")).alias("error")
        ).limit(100)
        
        sample_output = f"{args.output}/predictions_sample/{model_name}"
        print(f"[INFO] ä¿å­˜é¢„æµ‹æ ·ä¾‹åˆ°: {sample_output}")
        predictions_sample.coalesce(1).write.mode("overwrite").option("header", "true").csv(sample_output)

        # è®°å½•æŒ‡æ ‡
        metrics_list.append((model_name, float(rmse), float(mae), float(r2)))

    # ============================================================
    # ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„å¯¹æ¯”æŒ‡æ ‡
    # ============================================================
    metrics_output = f"{args.output}/metrics_comparison"
    print(f"\n[INFO] ä¿å­˜æ‰€æœ‰æ¨¡å‹å¯¹æ¯”æŒ‡æ ‡åˆ°: {metrics_output}")
    
    metrics_schema = ["model", "rmse", "mae", "r2"]
    metrics_df = spark.createDataFrame(metrics_list, metrics_schema)
    
    # ä¿å­˜ä¸º CSV
    metrics_df.coalesce(1).write.mode("overwrite").option("header", "true").csv(metrics_output + "_csv")
    
    # ä¿å­˜ä¸º JSON
    metrics_df.coalesce(1).write.mode("overwrite").json(metrics_output + "_json")

    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print("\n" + "="*80)
    print("æ‰€æœ‰æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("="*80)
    metrics_df.orderBy("rmse").show(truncate=False)

    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model = metrics_df.orderBy("rmse").first()
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['model']}")
    print(f"   RMSE: ${best_model['rmse']:.2f}")
    print(f"   MAE:  ${best_model['mae']:.2f}")
    print(f"   RÂ²:   {best_model['r2']:.4f}")

    print("\n[INFO] å¤šæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("\nğŸ“ è¾“å‡ºä½ç½®:")
    print(f"  - æ¨¡å‹æ–‡ä»¶:     {args.output}/models/")
    print(f"  - é¢„æµ‹æ ·ä¾‹:     {args.output}/predictions_sample/")
    print(f"  - ç‰¹å¾é‡è¦æ€§:   {args.output}/feature_importance/")
    print(f"  - æŒ‡æ ‡å¯¹æ¯”:     {args.output}/metrics_comparison_csv/")
    
    spark.stop()


if __name__ == "__main__":
    main()
